{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imagine que as redes neurais são como especialistas em diferentes áreas. Cada especialista é bom para resolver um tipo específico de problema.\n",
        "\n",
        "Neste script, vamos conhecer 4 \"especialistas\" diferentes:\n",
        "\n",
        "FNN (Feedforward Neural Network): O especialista básico.\n",
        "\n",
        "CNN (Convolutional Neural Network): O especialista em visão (imagens).\n",
        "\n",
        "RNN (Recurrent Neural Network): O especialista em sequências (texto, tempo).\n",
        "\n",
        "Reinforcement Learning (RL): O especialista que aprende por tentativa e erro."
      ],
      "metadata": {
        "id": "7h8A2z60-jsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 1: Redes Neurais de Fluxo Direto (FNN) - O Básico\n",
        "Analogia: O FNN é como um processo de decisão simples e unidirecional. As informações fluem de uma camada para a próxima, sem nunca voltar. É perfeito para problemas em que cada dado de entrada é independente do anterior.\n",
        "\n",
        "Caso de Uso: Classificar objetos com base em características fixas, como determinar se um e-mail é spam ou não."
      ],
      "metadata": {
        "id": "SULpG9Vg-3-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 1. Configuração e Exemplo de FNN\n",
        "# =================================================================\n",
        "\n",
        "# Importando bibliotecas\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"Parte 1: Exemplo de FNN com o dataset Iris\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Carregando um dataset clássico: a flor Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividindo os dados para treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizando os dados (uma boa prática)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Criando o modelo FNN\n",
        "model_fnn = keras.Sequential([\n",
        "    # Camada de entrada (input_shape define o formato dos dados)\n",
        "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    # Camada densa com 32 neurônios\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    # Camada de saída com 3 neurônios (uma para cada tipo de flor)\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilando e treinando o modelo\n",
        "model_fnn.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_fnn.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "loss, accuracy = model_fnn.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Acurácia do modelo FNN: {accuracy:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4N1fXpl-5l1",
        "outputId": "edeb10a4-ac55-437a-f71d-18f6a6a0b31b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parte 1: Exemplo de FNN com o dataset Iris\n",
            "--------------------------------------------------\n",
            "Acurácia do modelo FNN: 0.9000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 2: Redes Neurais Convolucionais (CNN) - Para o Mundo Visual\n",
        "Analogia: O CNN é como um detetive visual. Em vez de olhar para a imagem inteira de uma vez, ele escaneia a imagem em pequenas partes (como um microscópio) para encontrar padrões, como bordas, texturas e formas. Depois, ele junta esses padrões para identificar o que está na imagem.\n",
        "\n",
        "Caso de Uso: Classificação de imagens, detecção de objetos em fotos, reconhecimento facial."
      ],
      "metadata": {
        "id": "hFy6Ozp8_BtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 2. Configuração e Exemplo de CNN\n",
        "# =================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Parte 2: Exemplo de CNN com o dataset Fashion-MNIST\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Carregando o dataset de imagens de roupas\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Preparando os dados para o modelo\n",
        "train_images = train_images.reshape(-1, 28, 28, 1) / 255.0\n",
        "test_images = test_images.reshape(-1, 28, 28, 1) / 255.0\n",
        "\n",
        "# Criando o modelo CNN\n",
        "model_cnn = keras.Sequential([\n",
        "    # Camada Convolucional: encontra padrões na imagem\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    # Camada de Pooling: reduz a imagem, mantendo apenas os padrões mais importantes\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    # Outra camada convolucional\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    # \"Achatando\" os dados para que possam ser processados por uma camada FNN\n",
        "    keras.layers.Flatten(),\n",
        "    # Camada densa\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    # Camada de saída com 10 classes (uma para cada tipo de roupa)\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilando e treinando o modelo\n",
        "model_cnn.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_cnn.fit(train_images, train_labels, epochs=1, verbose=0) # Treinando por apenas 1 época para ser rápido\n",
        "\n",
        "loss, accuracy = model_cnn.evaluate(test_images, test_labels, verbose=0)\n",
        "print(f\"Acurácia do modelo CNN: {accuracy:.4f}\")\n",
        "\n",
        "# Mostrando um exemplo de imagem\n",
        "plt.figure()\n",
        "plt.imshow(test_images[0].reshape(28, 28), cmap='gray')\n",
        "plt.title(\"Exemplo de Imagem para a CNN\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "nWuixcsa_EtA",
        "outputId": "01f899bc-2ea5-4c99-9955-6f404ea8bdfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parte 2: Exemplo de CNN com o dataset Fashion-MNIST\n",
            "--------------------------------------------------\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo CNN: 0.8625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 3: Redes Neurais Recorrentes (RNN) e suas Evoluções - Para Sequências\n",
        "Analogia: O RNN é como uma pessoa que lê uma frase. Para entender o significado de uma palavra, ela precisa se lembrar das palavras anteriores. O RNN tem um \"laço de memória\" que permite que ele se lembre de informações passadas.\n",
        "\n",
        "Evolução (LSTM): Redes como a LSTM (Long Short-Term Memory) são uma evolução do RNN. Elas resolvem um problema comum dos RNNs: a dificuldade de se lembrar de informações que estão muito distantes no tempo (a chamada \"memória de longo prazo\"). A LSTM tem mecanismos para decidir o que lembrar e o que esquecer.\n",
        "\n",
        "Caso de Uso: Tradução de idiomas, predição de texto, análise de sentimento em resenhas de filmes."
      ],
      "metadata": {
        "id": "WsbkMuY0_nGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 3. Configuração e Exemplo de RNN (LSTM)\n",
        "# =================================================================\n",
        "\n",
        "print(\"\\nParte 3: Exemplo de RNN (LSTM) com o dataset IMDB (resenhas de filmes)\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Carregando o dataset de resenhas de filmes (classificação de sentimento)\n",
        "imdb = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Preparando os dados: preenchendo as resenhas para que todas tenham o mesmo tamanho\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=256)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, maxlen=256)\n",
        "\n",
        "# Criando o modelo LSTM\n",
        "model_lstm = keras.Sequential([\n",
        "    # Camada de embedding: converte palavras em vetores de números\n",
        "    keras.layers.Embedding(10000, 16),\n",
        "    # Camada LSTM: a \"memória\" que processa a sequência de palavras\n",
        "    keras.layers.LSTM(32),\n",
        "    # Camada densa de saída\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilando e treinando o modelo\n",
        "model_lstm.compile(optimizer='adam',\n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "model_lstm.fit(train_data, train_labels, epochs=1, verbose=0) # Treinando por apenas 1 época\n",
        "loss, accuracy = model_lstm.evaluate(test_data, test_labels, verbose=0)\n",
        "print(f\"Acurácia do modelo LSTM: {accuracy:.4f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRGwdLmW_vdo",
        "outputId": "72b56c3b-4547-40d5-9c2a-7dad6687ad0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parte 3: Exemplo de RNN (LSTM) com o dataset IMDB (resenhas de filmes)\n",
            "--------------------------------------------------\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Acurácia do modelo LSTM: 0.8496\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 4: Aprendizagem por Reforço (Reinforcement Learning) - O Mundo da Ação\n",
        "Analogia: O Reinforcement Learning (RL) é como um robô aprendendo a andar. Ele não é treinado com um dataset pré-existente. Em vez disso, ele explora um ambiente. Se ele cair, recebe uma \"punição\" (recompensa negativa). Se ele ficar de pé, recebe uma \"recompensa\". O objetivo é aprender a tomar as melhores ações para maximizar as recompensas ao longo do tempo.\n",
        "\n",
        "Diferença Fundamental: Diferente das outras redes neurais (que são exemplos de aprendizagem supervisionada), o RL não tem uma \"resposta correta\" no início. Ele descobre a resposta sozinho por tentativa e erro.\n",
        "\n",
        "Caso de Uso: Jogos de videogame, robótica, controle de tráfego, gestão de recursos."
      ],
      "metadata": {
        "id": "7Yj8pPPO_2y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================================================\n",
        "# 4. Configuração e Exemplo de Reinforcement Learning (RL)\n",
        "# =================================================================\n",
        "\n",
        "# Para este exemplo, usaremos o Gym (agora Gymnasium), uma biblioteca padrão para RL\n",
        "# Ele simula ambientes de jogos para testar os agentes.\n",
        "\n",
        "# Para instalar o Gymnasium, use a linha abaixo no Colab:\n",
        "# !pip install gymnasium\n",
        "\n",
        "import gymnasium as gym\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"Parte 4: Exemplo de Reinforcement Learning com o jogo 'CartPole'\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Neste jogo, um agente deve manter um mastro equilibrado em um carrinho.\\nEle recebe recompensas por cada passo que o mastro fica de pé.\")\n",
        "\n",
        "# Criando o ambiente do jogo CartPole\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
        "observation, info = env.reset(seed=42)\n",
        "\n",
        "# Simulando um \"agente\" que toma decisões aleatórias\n",
        "# Na vida real, o agente seria um modelo que aprende a melhor ação\n",
        "num_episodes = 2\n",
        "for episode in range(num_episodes):\n",
        "    terminated = False\n",
        "    truncated = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not terminated and not truncated:\n",
        "        # O agente escolhe uma ação aleatória: 0 (mover para a esquerda) ou 1 (mover para a direita)\n",
        "        action = env.action_space.sample()\n",
        "\n",
        "        # O agente executa a ação e o ambiente retorna o resultado\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "        total_reward += reward\n",
        "\n",
        "        # Mostrando a simulação (somente funciona em ambientes interativos como o Jupyter)\n",
        "        # Se você estiver em um ambiente que não renderiza, você ainda pode ver os prints\n",
        "        # print(f\"Passo: {env.step_count}, Ação: {action}, Recompensa: {reward}\")\n",
        "\n",
        "    print(f\"Episódio {episode + 1} finalizado. Recompensa total: {total_reward}\")\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYmTPBxqAGJJ",
        "outputId": "048edaf9-f492-4f34-b1f5-135501391aeb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parte 4: Exemplo de Reinforcement Learning com o jogo 'CartPole'\n",
            "--------------------------------------------------\n",
            "Neste jogo, um agente deve manter um mastro equilibrado em um carrinho.\n",
            "Ele recebe recompensas por cada passo que o mastro fica de pé.\n",
            "Episódio 1 finalizado. Recompensa total: 23.0\n",
            "Episódio 2 finalizado. Recompensa total: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/classic_control/cartpole.py:214: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    }
  ]
}